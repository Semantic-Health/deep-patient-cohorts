{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy Labeling of Clinical Notes\n",
    "\n",
    "This notebook allows you to assign \"noisy\" labels to clinical notes using heuristics known as labelling functions (LFs).\n",
    "\n",
    "Because this is a largely exploratory process, it may be useful to run the following cell, which allows you to modify the `NoisyLabeler` code without restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "First, you must load some text to label. You will want to have some source of \"gold\" labels to determine the accuracy of your labelling functions. Your labels should be `1`, indicating the presence of a disease, or `0`, indicating its absence. The following code assumes your data is in a [JSON Lines](https://jsonlines.org/) format, with the fields `\"text\"` and `\"label\"`, but you can load the data any way you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data_filepath = \"../data/MIMIC-III-HEART-DISEASE/valid.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "valid = [json.loads(line) for line in Path(gold_data_filepath).read_text().strip().split(\"\\n\")]\n",
    "texts = [example[\"text\"] for example in valid]\n",
    "labels = np.asarray([example[\"label\"] for example in valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Noisy) Label the Data\n",
    "\n",
    "First, initialize the labeller\n",
    "\n",
    "> Note, this can take a few minutes as it loads the language model and resources into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_patient_cohorts import NoisyLabeler\n",
    "\n",
    "labeler = NoisyLabeler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although optional, it makes sense to preprocess the text with spaCy only one. We can do this easily like so\n",
    "\n",
    "> Note, this will take a few minutes per 1000 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = labeler.preprocess(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, label the data and check the accuracy of each labelling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_labels = labeler.fit_lfs(processed_texts)\n",
    "_ = labeler.accuracy(noisy_labels=noisy_labels, gold_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 LF 0: Accuracy 56%, Abstain rate 45%\n",
    "2 LF 0: Accuracy 61%, Abstain rate 67%\n",
    "3\n",
    "\n",
    "neg\n",
    "1 LF 0: Accuracy 61%, Abstain rate 0%\n",
    "2 LF 0: Accuracy 65%, Abstain rate 22%\n",
    "3 LF 0: Accuracy 66%, Abstain rate 35%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding New LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to continually modify your LFs until they reach acceptable accuracy. The following example demonstrates how to add a new LF to the existing `labeler`, and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from deep_patient_cohorts import POSITIVE, NEGATIVE, ABSTAIN\n",
    "\n",
    "def heart_disease(self, texts: List[str]) -> List[int]:\n",
    "    return [POSITIVE if \"heart disease\" in text.text.lower() else ABSTAIN for text in texts]\n",
    "\n",
    "labeler.add(heart_disease)\n",
    "\n",
    "noisy_labels = labeler.fit_lfs(processed_texts)\n",
    "labeler.accuracy(noisy_labels=noisy_labels, gold_labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can also modify the `NoisyLabeler` code directly.\n",
    "\n",
    "### Training a Label Model\n",
    "\n",
    "Using [FlyingSquid](https://github.com/HazyResearch/flyingsquid), we can train a probablistic model to combine our LFs (assuming we have at least 3!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler.fit_lm(noisy_labels=noisy_labels, gold_labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can fit both the labelling functions and the label models in one step with\n",
    "\n",
    "```python\n",
    "labeler.fit(noisy_labels=noisy_labels, gold_labels=labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing LFs\n",
    "\n",
    "If it turns out our new LF performs poorly, we can remove it and try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del labeler.lfs[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-patient-cohorts",
   "language": "python",
   "name": "deep-patient-cohorts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
