{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy Labeling of Clinical Notes\n",
    "\n",
    "This notebook allows you to assign \"noisy\" labels to clinical notes using heuristics known as labelling functions (LFs).\n",
    "\n",
    "Because this is a largely exploratory process, it may be useful to run the following cell, which allows you to modify the `NoisyLabeler` code without restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/karthik/Desktop/karthik-wanglab/deep-patient-cohorts/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "First, you must load some text to label. You will want to have some source of \"gold\" labels to determine the accuracy of your labelling functions. Your labels should be `1`, indicating the presence of a disease, or `0`, indicating its absence. The following code assumes your data is in a [JSON Lines](https://jsonlines.org/) format, with the fields `\"text\"` and `\"label\"`, but you can load the data any way you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data_filepath = \"../data/MIMIC-III-HEART-DISEASE/valid.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "valid = [json.loads(line) for line in Path(gold_data_filepath).read_text().strip().split(\"\\n\")]\n",
    "texts = [example[\"text\"] for example in valid]\n",
    "labels = np.asarray([example[\"label\"] for example in valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Noisy) Label the Data\n",
    "\n",
    "First, initialize the labeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_patient_cohorts import NoisyLabeler\n",
    "\n",
    "labeler = NoisyLabeler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although optional, it makes sense to preprocess the text with spaCy only one. We can do this easily like so\n",
    "\n",
    "> note, this will take a few minutes per 1000 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5272it [12:13,  7.19it/s] \n"
     ]
    }
   ],
   "source": [
    "texts = labeler.preprocess(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can label the data and check the accuracy of each labelling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:53<00:00, 23.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF 0: Accuracy 61%, Abstain rate 68%\n",
      "LF 1: Accuracy 54%, Abstain rate 83%\n",
      "LF 2: Accuracy 58%, Abstain rate 97%\n",
      "LF 3: Accuracy 72%, Abstain rate 88%\n",
      "LF 4: Accuracy 61%, Abstain rate 95%\n",
      "LF 5: Accuracy 86%, Abstain rate 78%\n",
      "LF 6: Accuracy 82%, Abstain rate 96%\n",
      "LF 7: Accuracy 61%, Abstain rate 81%\n",
      "LF 8: Accuracy 63%, Abstain rate 55%\n",
      "LF 9: Accuracy 57%, Abstain rate 97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "noisy_labels = labeler(texts)\n",
    "\n",
    "labeler.accuracy(noisy_labels=noisy_labels, gold_labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding New LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to continually modify your LFs until they reach acceptable accuracy. The following example demonstrates how to add a new LF to the existing `labeler`, and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from typing import List\n",
    "from deep_patient_cohorts import POSITIVE, NEGATIVE, ABSTAIN\n",
    "\n",
    "\n",
    "# heart_disease\n",
    "def heart_disease(self, texts: List[str]) -> List[int]:\n",
    "    return [POSITIVE if \"heart disease\" in text.text.lower() else ABSTAIN for text in texts]\n",
    "\n",
    "\n",
    "labeler.add(heart_disease)\n",
    "\n",
    "noisy_labels = labeler(texts)\n",
    "labeler.accuracy(noisy_labels=noisy_labels, gold_labels=labels)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can also modify the `NoisyLabeler` code directly.\n",
    "\n",
    "### Training a Label Model\n",
    "\n",
    "Using [FlyingSquid](https://github.com/HazyResearch/flyingsquid), we can train a probablistic model to combine our LFs (assuming we have at least 3!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label model accuracy: 62%\n"
     ]
    }
   ],
   "source": [
    "from flyingsquid.label_model import LabelModel\n",
    "\n",
    "m = noisy_labels.shape[1]\n",
    "label_model = LabelModel(m)\n",
    "\n",
    "label_model.fit(noisy_labels)\n",
    "\n",
    "preds = label_model.predict(noisy_labels).reshape(labels.shape)\n",
    "accuracy = np.sum(preds == labels) / labels.shape[0]\n",
    "\n",
    "print(f\"Label model accuracy: {int(100 * accuracy)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing LFs\n",
    "\n",
    "If it turns out our new LF performs poorly, we can remove it and try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del labeler.lfs[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler.lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
