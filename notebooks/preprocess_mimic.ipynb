{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess MIMIC-III\n",
    "\n",
    "This notebook will preprocess MIMIC-III for use with [AllenNLP-multi-label](https://github.com/semantic-health/allennlp-multi-label) and [Deep Patient Cohorts](https://github.com/semantic-health/deep-patient-cohorts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "First, download the `\"NOTEEVENTS.csv\"` and `\"DIAGNOSES_ICD.csv\"` files from https://physionet.org/content/mimiciii, then set their filepaths below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noteevents_filepath = \"\"\n",
    "diagnoses_icd_filepath = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these files, we will create a table containing the text of the discharge summaries and their corresponding ICD9 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deep_patient_cohorts.common.utils import reformat_icd_code\n",
    "\n",
    "noteevents = pd.read_csv(\n",
    "    noteevents_filepath,\n",
    "    index_col=\"HADM_ID\",\n",
    "    usecols=[\"HADM_ID\", \"TEXT\", \"CATEGORY\"],\n",
    "    dtype={\"HADM_ID\": str, \"CATEGORY\": str},\n",
    "    # Remove whitespace, newlines and tabs from TEXT column data.\n",
    "    converters={\"TEXT\": lambda text: \" \".join(str(text).strip().split())},\n",
    ")\n",
    "\n",
    "diagnoses_icd = pd.read_csv(\n",
    "    diagnoses_icd_filepath,\n",
    "    index_col=\"HADM_ID\",\n",
    "    usecols=[\"HADM_ID\", \"ICD9_CODE\"],\n",
    "    dtype={\"HADM_ID\": str},\n",
    "    # MIMIC-III ICD9 codes need to be formatted\n",
    "    converters={\"ICD9_CODE\": reformat_icd_code}\n",
    ")\n",
    "\n",
    "# Postprocessing steps...\n",
    "# ...filter out anything that isn't a discharge summary\n",
    "noteevents = noteevents[noteevents[\"CATEGORY\"] == \"Discharge summary\"].drop(\"CATEGORY\", axis=1)\n",
    "# ...convert long format data to wide-ish format data\n",
    "noteevents = noteevents.groupby('HADM_ID')['TEXT'].apply(list).to_frame()\n",
    "diagnoses_icd = diagnoses_icd.groupby('HADM_ID')['ICD9_CODE'].apply(list).to_frame()\n",
    "# ...if there is more than one note per HADM_ID, take the longest\n",
    "noteevents[\"TEXT\"] = noteevents[\"TEXT\"].map(lambda x: max(x, key=len))\n",
    "\n",
    "df = noteevents.join(diagnoses_icd)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "labels = list(chain.from_iterable(df[\"ICD9_CODE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "a = ['a', 'a', 'a', 'a', 'b', 'b', 'c', 'c', 'c', 'd', 'e', 'e', 'e', 'e', 'e']\n",
    "counts = Counter(labels)\n",
    "df = pd.DataFrame.from_dict(counts, orient='index')\n",
    "# df.plot(kind='bar')\n",
    "\n",
    "print(len(counts))\n",
    "print(len([value for value in list(counts.values()) if value <=10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we remove sections that aren't relevant for predicting the patients diagnosis. Note, this may take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clinical_sectionizer import TextSectionizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "blacklist = {\n",
    "    'allergy',\n",
    "    'family_history',\n",
    "    'hiv_screening',\n",
    "    'other',\n",
    "    'education',\n",
    "    'past_medical_history',\n",
    "    'patient_instructions',\n",
    "    'patient_instructions',\n",
    "    'sexual_and_social_history'\n",
    "    'signature',\n",
    "    #'labs_and_studies'\n",
    "}\n",
    "sectionizer = TextSectionizer()\n",
    "processed_text = []\n",
    "for text in tqdm(df[\"TEXT\"].tolist()):\n",
    "    processed_text.append(\n",
    "        \"\\n\".join([section for (title, _, section) in sectionizer(text) if title not in blacklist])\n",
    "    )\n",
    "df[\"TEXT\"] = processed_text\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map ICD9 codes to SNOWMED CT Identifiers\n",
    "\n",
    "Then, download the [ICD-9-CM Diagnostic Codes to SNOMED CT Map](https://www.nlm.nih.gov/research/umls/mapping_projects/icd9cm_to_snomedct.html) and set the paths below to the `ICD9CM_SNOMED_MAP_1TO1_20****.txt` and `ICD9CM_SNOMED_MAP_1TOM_20****.txt` text files below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd9cm_to_snowmed_1to1_filepath = \"\"\n",
    "icd9cm_to_snowmed_1tom_filepath = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use these files to create a mapping from ICD9 codes to their corresponding SNOWMED CIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pprint import pprint\n",
    "\n",
    "snowmed_1to1 = pd.read_csv(\n",
    "    icd9cm_to_snowmed_1to1_filepath,\n",
    "    sep=\"\\t\",\n",
    "    usecols=[\"ICD_CODE\", \"SNOMED_CID\"],\n",
    "    dtype={\"ICD_CODE\": str, \"SNOMED_CID\": str}\n",
    ").dropna().groupby('ICD_CODE')['SNOMED_CID'].apply(list)\n",
    "\n",
    "snowmed_1tom = pd.read_csv(\n",
    "    icd9cm_to_snowmed_1tom_filepath,\n",
    "    sep=\"\\t\",\n",
    "    usecols=[\"ICD_CODE\", \"SNOMED_CID\"],\n",
    "    dtype={\"ICD_CODE\": str, \"SNOMED_CID\": str}\n",
    ").dropna().groupby('ICD_CODE')['SNOMED_CID'].apply(list)\n",
    "\n",
    "for key, value in snowmed_1tom.items():\n",
    "    if key in snowmed_1to1:\n",
    "        snowmed_1to1[key].extend(**value)\n",
    "    else:\n",
    "        snowmed_1to1[key] = value\n",
    "        \n",
    "icd_to_snowmed_map = snowmed_1to1.to_dict()\n",
    "pprint(dict(itertools.islice(icd_to_snowmed_map.items(), 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def icd9_to_snowmed(icd9_codes: List[str]):\n",
    "    return list(set(itertools.chain.from_iterable(icd_to_snowmed_map[code] for code in icd9_codes if code in icd_to_snowmed_map)))\n",
    "\n",
    "df['SNOMED_CID'] = df['ICD9_CODE'].map(icd9_to_snowmed)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollup the SNOWMED CT Identifiers\n",
    "\n",
    "Next, you will need to download a SNOWMED release, and set the filepath below to the full \"Relationship_Full\" text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships_filepath = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IS_A_CID = \"116680003\"\n",
    "\n",
    "snowmed_relationships = pd.read_csv(\n",
    "    relationships_filepath,\n",
    "    sep=\"\\t\",\n",
    "    usecols=[\"sourceId\", \"destinationId\", \"typeId\"],\n",
    "    dtype={\"sourceId\": str, \"destinationId\": str, \"typeId\": str},\n",
    ")\n",
    "\n",
    "snowmed_relationships = snowmed_relationships[snowmed_relationships[\"typeId\"] == IS_A_CID]\n",
    "snowmed_relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a hack to get the IDs of all the concepts under the Clinical Finding > Disease branch of SNOWMED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was copy/pasted from: https://uts.nlm.nih.gov/snomedctBrowser.html;jsessionid=59F3153C7129757C034B75CE3340662C#A2880798;1;0;AUI;undefined;SNOMEDCT_US;undefined;false;\n",
    "# A much more desirable solution would be to automatically determine children from the SNOWMED release files.\n",
    "heart_disease_children = \"\"\"\n",
    "Abnormal fetal heart beat first noted during labor AND/OR delivery in liveborn infant [\n",
    "\t22271007\t\n",
    "]\n",
    "Acute heart disease [\n",
    "\t127337006\t\n",
    "]\n",
    "Anomalous bands of heart [\n",
    "\t204407002\t\n",
    "]\n",
    "Athlete's heart [\n",
    "\t233931008\t\n",
    "]\n",
    "Cardiac abnormality due to heart abscess [\n",
    "\t461089003\t\n",
    "]\n",
    "Cardiac arrhythmia [\n",
    "\t698247007\t\n",
    "]\n",
    "Cardiac complication [\n",
    "\t40172005\t\n",
    "]\n",
    "Cardiac complication of anesthesia during the puerperium [\n",
    "\t717959008\t\n",
    "]\n",
    "Cardiac complication of procedure [\n",
    "\t362999008\t\n",
    "]\n",
    "Cardiac disease in pregnancy [\n",
    "\t274121004\t\n",
    "]\n",
    "Cardiac disorder due to typhoid fever [\n",
    "\t1084791000119106\t\n",
    "]\n",
    "Cardiac glycogen phosphorylase kinase deficiency [\n",
    "\t297253000\t\n",
    "]\n",
    "Chronic heart disease [\n",
    "\t128238001\t\n",
    "]\n",
    "Cyanotic congenital heart disease [\n",
    "\t12770006\t\n",
    "]\n",
    "Disorder of atrium following procedure [\n",
    "\t735584007\t\n",
    "]\n",
    "Disorder of cardiac function [\n",
    "\t105981003\t\n",
    "]\n",
    "Disorder of cardiac ventricle [\n",
    "\t415991003\t\n",
    "]\n",
    "Disorder of coronary artery [\n",
    "\t414024009\t\n",
    "]\n",
    "Disorder of left atrium [\n",
    "\t472763005\t\n",
    "]\n",
    "Disorder of right atrium [\n",
    "\t472762000\t\n",
    "]\n",
    "Disorder of transplanted heart [\n",
    "\t429257001\t\n",
    "]\n",
    "Endocardial disease [\n",
    "\t123596001\t\n",
    "]\n",
    "Fetal heart disorder [\n",
    "\t430901004\t\n",
    "]\n",
    "Healed bacterial endocarditis [\n",
    "\t123597005\t\n",
    "]\n",
    "Heart disease co-occurrent with human immunodeficiency virus infection [\n",
    "\t713298006\t\n",
    "]\n",
    "Heart disease due to ionizing radiation [\n",
    "\t430401005\t\n",
    "]\n",
    "Heart disease in mother complicating pregnancy, childbirth AND/OR puerperium [\n",
    "\t78381004\t\n",
    "]\n",
    "Heart valve disorder [\n",
    "\t368009\t\n",
    "]\n",
    "Hypertensive heart disease [\n",
    "\t64715009\t\n",
    "]\n",
    "Induced termination of pregnancy complicated by cardiac arrest and/or failure [\n",
    "\t609460008\t\n",
    "]\n",
    "Infectious disease of heart [\n",
    "\t128403000\t\n",
    "]\n",
    "Mechanical complication due to heart valve prosthesis [\n",
    "\t43873004\t\n",
    "]\n",
    "Myocardial disease [\n",
    "\t57809008\t\n",
    "]\n",
    "Myxedema heart disease [\n",
    "\t4641009\t\n",
    "]\n",
    "Outflow tract abnormality in solitary indeterminate ventricle [\n",
    "\t448898002\t\n",
    "]\n",
    "Pulmonary heart disease [\n",
    "\t274096000\t\n",
    "]\n",
    "Rheumatic heart disease [\n",
    "\t23685000\t\n",
    "]\n",
    "Sinistrocardia [\n",
    "\t424889004\t\n",
    "]\n",
    "Structural disorder of heart [\n",
    "\t128599005\t\n",
    "]\n",
    "Thyrotoxic heart disease [\n",
    "\t60446003\t\n",
    "]\n",
    "Ventricular tachycardia [\n",
    "\t25569003\t\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_ids = [line.split(\"\\t\")[1] for line in heart_disease_children.split(\"\\n\") if line and len(line.split(\"\\t\")) == 3]\n",
    "\n",
    "rollup_map = {}\n",
    "for cid in heart_disease_ids:\n",
    "    children = snowmed_relationships[snowmed_relationships[\"destinationId\"] == cid][\"sourceId\"].unique().tolist()\n",
    "    rollup_map.update(dict.fromkeys(children, cid))\n",
    "pprint(dict(itertools.islice(rollup_map.items(), 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will roll up all the SNOWMED CIDs to the level of \"Heart disease\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snowmed_cid_rollup(cids: List[str]):\n",
    "    return [rollup_map[cid] for cid in cids if cid in rollup_map]\n",
    "\n",
    "df['SNOMED_HEART_DISEASE_CID'] = df['SNOMED_CID'].map(snowmed_cid_rollup)\n",
    "df['IS_HEART_DISEASE'] = df['SNOMED_HEART_DISEASE_CID'].map(lambda x: 1 if x else -1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we can check the fraction of notes that were mapped to at least one SNOWMED Disease CID\n",
    "\n",
    "> Note, 100% of notes are labelled with one or more ICD9 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{sum([True for labels in df['SNOMED_HEART_DISEASE_CID'] if labels]) / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Data\n",
    "\n",
    "First, we partion the dataset into stratified train, validation and test splits. Then we will save it in a format that is suitable for use with [AllenNLP-multi-label](https://github.com/semantic-health/allennlp-multi-label) and [Deep Patient Cohorts](https://github.com/semantic-health/deep-patient-cohorts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the filepath to save the data as stratified train/valid/test folds (70%/10%/20% splits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../data/MIMIC-III-HEART-DISEASE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def save_data(text: np.ndarray, labels: np.ndarray, output_dir: str, use_string_labels: bool = False) -> None:\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    text = df[[\"TEXT\"]].values\n",
    "    labels = df[\"IS_HEART_DISEASE\"].values\n",
    "    \n",
    "    if use_string_labels:\n",
    "        labels = np.where(labels==1, \"heart_disease\", \"no_heart_disease\")\n",
    "\n",
    "    train_size = 0.7\n",
    "    valid_size = 0.1\n",
    "    test_size = 0.2\n",
    "\n",
    "    # https://datascience.stackexchange.com/a/53161\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        text, labels, test_size=1 - train_size, stratify=labels\n",
    "    )\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "        X_test, y_test, test_size=test_size/(test_size + valid_size), stratify=y_test\n",
    "    )\n",
    "\n",
    "    X_train = X_train.ravel()\n",
    "    X_valid = X_valid.ravel()\n",
    "    X_test = X_test.ravel()\n",
    "    \n",
    "    y_train = y_train.tolist()\n",
    "    y_valid = y_valid.tolist()\n",
    "    y_test = y_test.tolist()\n",
    "\n",
    "    with open(output_dir / \"train.jsonl\", \"w\") as f:\n",
    "        for t, l in zip(X_train, y_train):\n",
    "            f.write(f\"{json.dumps({'text': t, 'label': l})}\\n\")\n",
    "    with open(output_dir / \"valid.jsonl\", \"w\") as f:\n",
    "        for t, l in zip(X_valid, y_valid):\n",
    "            f.write(f\"{json.dumps({'text': t, 'label': l})}\\n\")\n",
    "    with open(output_dir / \"test.jsonl\", \"w\") as f:\n",
    "        for t, l in zip(X_test, y_test):\n",
    "            f.write(f\"{json.dumps({'text': t, 'label': l})}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[[\"TEXT\"]].values\n",
    "labels = df[\"IS_HEART_DISEASE\"].values\n",
    "\n",
    "save_data(text, labels, output_dir, use_string_labels=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-patient-cohorts",
   "language": "python",
   "name": "deep-patient-cohorts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
